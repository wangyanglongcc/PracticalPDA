import collections
import jieba.posseg as pseg

text = """普通安装方法是pip官方的包，但这种大街货往往没有针对本地环境做优化。比如调用时会警告说你的机器支持一些可加速运算的指令，但编译时没有启用，让你心痒难耐。"""
text = text.strip()
# 词频统计
word_freq = dict(collections.Counter(jieba.cut(text)))
print(word_freq)
# {'普通': 1, '安装': 1, '方法': 1, '是': 1, 'pip': 1, '官方': 1, '的': 3, '包': 1, '，': 3,
# '但': 2, '这种': 1, '大街': 1, '货': 1, '往往': 1, '没有': 2, '针对': 1, '本地': 1, '环境': 1,
# '做': 1, '优化': 1, '。': 2, '比如': 1, '调用': 1, '时会': 1,
# '警告': 1, '说': 1, '你': 2, '机器': 1, '支持': 1, '一些': 1, '可': 1, '加速': 1, '运算': 1, '指令': 1,
# '编译': 1, '时': 1, '启用': 1, '让': 1, '心痒': 1, '难耐': 1}
# 下面开始对字典按照值进行降序排列
print(sorted(word_freq.items(),key=lambda x:x[1],reverse=True))# 默认升序,reverse=False
# [('的', 3), ('，', 3), ('但', 2), ('没有', 2), ('。', 2), ('你', 2), ('普通', 1), 
# ('安装', 1), ('方法', 1), ('是', 1), ('pip', 1), ('官方', 1), ('包', 1), ('这种', 1),
# ('大街', 1), ('货', 1), ('往往', 1), ('针对', 1), ('本地', 1), ('环境', 1), ('做', 1), 
# ('优化', 1), ('比如', 1), ('调用', 1), ('时会', 1), ('警告', 1), ('说', 1), ('机器', 1),
# ('支持', 1), ('一些', 1), ('可', 1), ('加速', 1), ('运算', 1), ('指令', 1), ('编译', 1), 
# ('时', 1), ('启用', 1), ('让', 1), ('心痒', 1), ('难耐', 1)]
# 这里返回的结果也可以直接转为DataFrame,只需要在外层套一层pd.DataFrame()即可
# 词性统计
flags =(flag for word,flag in pseg.cut(text))
flags = dict(collections.Counter(list(flags)))
print(flags)
# {'nz': 1, 'v': 15, 'n': 9, 'eng': 1, 'uj': 3, 'x': 5, 'c': 2, 'r': 4, 'ns': 1, 't': 1, 'p': 1, 'vn': 3, 'm': 1, 'a': 1}
print(sorted(flags.items(),key=lambda x:x[1],reverse=True))
# [('v', 15), ('n', 9), ('x', 5), ('r', 4), ('uj', 3), ('vn', 3), ('c', 2), ('nz', 1), ('eng', 1), ('ns', 1), ('t', 1), ('p', 1), ('m', 1), ('a', 1)]
